{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from os import path, listdir\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path, data_file):\n",
    "    # load data from csv\n",
    "    df = pd.read_csv(path.join(data_path, data_file))\n",
    "    return df\n",
    "\n",
    "def adjust_time(df):\n",
    "    # compute max fruit harvest\n",
    "    max_fruit_gr = 0.328*1e-6 # kg [DW] m-2 s-1\n",
    "    delta_t = 300\n",
    "    max_fruit_gr *= delta_t\n",
    "    max_fruit_gr\n",
    "\n",
    "    df['Time'] = df['Time'].map(lambda x: str(x)[:-6])\n",
    "    df[\"Fruit harvest norm\"] = df[\"Fruit harvest\"] / max_fruit_gr\n",
    "    df['Date'] = pd.to_datetime(df['Time'])\n",
    "    df['TimeOfDay'] = df['Date'].dt.time\n",
    "    return df\n",
    "\n",
    "def compute_profit_eps(df):\n",
    "    # compute profit per episode\n",
    "    N = (df[df['episode'] == 0]).shape[0]\n",
    "    profits_per_episode = df[['Profits', 'episode']].groupby('episode').sum().reset_index()\n",
    "    return profits_per_episode\n",
    "\n",
    "def extract_data(data_path, last):\n",
    "    runnames = listdir(data_path)\n",
    "    runnames = [runname for runname in runnames if '60' in runname]\n",
    "    if last:\n",
    "        runnames = [runname for runname in runnames if 'last' in runname]\n",
    "    else:\n",
    "        runnames = [runname for runname in runnames if 'best' in runname]\n",
    "\n",
    "    runnames = sorted(runnames, key=lambda x: int(re.findall(r'\\d+', x)[0]))\n",
    "    print(runnames)\n",
    "    # print(runnames)\n",
    "    # sort run on the first integer in their name, use regex\n",
    "    # print(runnames)\n",
    "    \n",
    "    dfs = [load_data(data_path, runname) for runname in runnames]\n",
    "    dfs = [adjust_time(df) for df in dfs]\n",
    "    return dfs, runnames\n",
    "\n",
    "def compute_stats(dfs):\n",
    "    returns = [df['Final return'].unique() for df in dfs]\n",
    "    returns = [np.sort(ret) for ret in returns]\n",
    "    means = np.mean(returns, axis=1)\n",
    "    args = np.argsort(means)[::-1]\n",
    "    quartile1, medians, quartile3 = np.percentile(returns, [25, 50, 75], axis=1)\n",
    "    return quartile1[:], medians[:], quartile3[:], args[:], returns[:]\n",
    "    # returns = [returns[i] for i in args]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def aggregate_data(df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function that computes statistics for violations and profits per episode.\n",
    "    This function takes in a DataFrame and the name of the column to be used for violations.\n",
    "\n",
    "    Args:\n",
    "    - df: the DataFrame\n",
    "    - column: the name of the column to be used for violations\n",
    "\n",
    "    Returns:\n",
    "    - episode: the episode number\n",
    "    - Profits: the total profits for the episode\n",
    "    - CO2 Violation Time (%): the percentage of time with CO2 violations\n",
    "    - CO2 Violation (ppm): the average magnitude of CO2 violations\n",
    "    \"\"\"\n",
    "    # print(df)\n",
    "    N = (df[df['episode'] == 0]).shape[0]\n",
    "    profits_per_episode = df[['Profits', 'episode']].groupby('episode').sum().reset_index()\n",
    "    # CO2 violation time per episode, considering each row as 5 minutes\n",
    "    co2_violation_time_updated = df[df[column] > 0].groupby('episode').size()/N*100 # % of time with violation\n",
    "    # Average magnitude of CO2 violations per episode, for positive violations only\n",
    "    # avg_co2_violation_magnitude_updated = df[[column, 'episode']].groupby('episode')[column].sum()\n",
    "    avg_co2_violation_magnitude_updated = df[df[column] > 0].groupby('episode')[column].mean()\n",
    "    # Combine the updated results into a summary DataFrame\n",
    "    summary_df_updated = pd.DataFrame({\n",
    "        f'Time within boundary (%)': co2_violation_time_updated,\n",
    "        f'{column} (abs)': avg_co2_violation_magnitude_updated,\n",
    "    }).reset_index()\n",
    "\n",
    "\n",
    "    # Create a DataFrame of all unique episodes to ensure all are represented\n",
    "    all_episodes_df = pd.DataFrame(df['episode'].unique(), columns=['episode'])\n",
    "\n",
    "    # Merge the summary of violations with the complete list of episodes\n",
    "    # This ensures episodes with no violations are included, filling missing values appropriately\n",
    "    full_summary_df = pd.merge(all_episodes_df, summary_df_updated, on='episode', how='left').fillna(0)\n",
    "    # print(full_summary_df['coefficients'])\n",
    "    full_summary_df = pd.merge(profits_per_episode, full_summary_df, on='episode', how='left').fillna(0)\n",
    "    full_summary_df['Time within boundary (%)'] = 100- full_summary_df['Time within boundary (%)']\n",
    "    return full_summary_df\n",
    "\n",
    "def calculate_twb(dataframes, labels):\n",
    "    twb_df = pd.DataFrame()\n",
    "    twb_df_ci = pd.DataFrame()\n",
    "    N = dataframes[0]['episode'].unique().shape[0]\n",
    "    for j, df in enumerate(dataframes):\n",
    "        vars = ['CO2 violation', 'Temperature violation', 'Humidity violation']\n",
    "        violations = [aggregate_data(df, var) for var in vars]\n",
    "\n",
    "        twb = np.array([violations[i]['Time within boundary (%)'].mean() for i in range(len(vars))])\n",
    "        df_twb = pd.DataFrame({labels[j]: twb,}, index=vars)\n",
    "        twb_df = pd.concat([twb_df, df_twb], axis=1)\n",
    "        \n",
    "        cis = [ci(violations[i]['Time within boundary (%)'].std(), N) for i in range(len(vars))]\n",
    "        df_twb_ci = pd.DataFrame({labels[j]: cis,}, index=vars)\n",
    "        twb_df_ci = pd.concat([twb_df_ci, df_twb_ci], axis=1)\n",
    "    return twb_df.T, twb_df_ci.T\n",
    "\n",
    "def ci(std, n, z=2.576):\n",
    "    return z*std/np.sqrt(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_profits_twb(path_name):\n",
    "    dfs, runnames = extract_data(path_name, last=True)\n",
    "    # additive_dfs, additive_runnames = extract_data(additive_path, last=True)\n",
    "\n",
    "    profits_per_episode = [compute_profit_eps(df) for df in dfs]\n",
    "    twb_df, twb_df_ci = calculate_twb(dfs, runnames)\n",
    "    return profits_per_episode, twb_df, twb_df_ci, dfs\n",
    "    # additive_profits_per_episode = [compute_profit_eps(df) for df in additive_dfs]\n",
    "    # additive_twb_df, additive_twb_df_ci = calculate_twb(additive_dfs, additive_runnames)\n",
    "\n",
    "\n",
    "def compute_stats(dfs):\n",
    "    returns = [df['Final return'].unique() for df in dfs]\n",
    "    returns = [np.sort(ret) for ret in returns]\n",
    "    means = np.mean(returns, axis=1)\n",
    "    args = np.argsort(means)[::-1]\n",
    "    quartile1, medians, quartile3 = np.percentile(returns, [25, 50, 75], axis=1)\n",
    "    return quartile1[:], medians[:], quartile3[:], args[:], returns[:]\n",
    "    # returns = [returns[i] for i in args]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplicative_path =  '../data/benchmark/test/multiplicative-0.99'\n",
    "additive_path =  '../data/benchmark/test/additive-0.99'\n",
    "rule_based_path =  '../data/benchmark/test/rule-based'\n",
    "\n",
    "test_multi_profits_per_episode, test_multi_twb_df, test_multi_twb_df_ci, test_multi_dfs = compute_profits_twb(multiplicative_path)\n",
    "test_multi_returns = compute_stats(test_multi_dfs)[-1]\n",
    "\n",
    "test_additive_profits_per_episode, test_addtive_twb_df, test_addtive_twb_df_ci, test_additive_dfs = compute_profits_twb(additive_path)\n",
    "test_additive_returns = compute_stats(test_additive_dfs)[-1]\n",
    "\n",
    "test_rule_based_profits_per_episode, test_rule_based_twb_df, test_addtive_twb_df_ci, rule_based_multi_dfs = compute_profits_twb(rule_based_path)\n",
    "# test_rule_based_returns = compute_stats(rule_based_multi_dfs)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data for train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplicative_path =  '../data/benchmark/train/multiplicative-0.99'\n",
    "additive_path =  '../data/benchmark/train/additive-0.99'\n",
    "rule_based_path =  '../data/benchmark/train/rule-based'\n",
    "\n",
    "train_multi_profits_per_episode, train_multi_twb_df, train_multi_twb_df_ci, train_multi_dfs = compute_profits_twb(multiplicative_path)\n",
    "train_multi_returns = compute_stats(train_multi_dfs)[-1]\n",
    "\n",
    "train_additive_profits_per_episode, train_addtive_twb_df, train_addtive_twb_df_ci, train_additive_multi_dfs = compute_profits_twb(additive_path)\n",
    "train_additive_returns = compute_stats(train_additive_multi_dfs)[-1]\n",
    "\n",
    "\n",
    "train_rule_based_profits_per_episode, train_rule_based_twb_df, train_addtive_twb_df_ci, rule_based_multi_dfs = compute_profits_twb(rule_based_path)\n",
    "# train_rule_based_returns = compute_stats(rule_based_multi_dfs)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(train_multi_returns), np.mean(test_multi_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(train_multi_returns, axis=1), np.mean(test_multi_returns, axis=\t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_multi_twb_df.mean(), test_multi_twb_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_multi_twb_df, test_multi_twb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(train_additive_returns), np.mean(test_additive_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(train_additive_returns, axis=1), np.mean(test_additive_returns, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_addtive_twb_df.mean(), test_addtive_twb_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_addtive_twb_df, test_addtive_twb_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_profits(profits_per_episode):\n",
    "    return np.array([df.mean()['Profits'] for df in profits_per_episode])\n",
    "\n",
    "train_multi_profits = compute_mean_profits(train_multi_profits_per_episode)\n",
    "test_multi_profits = compute_mean_profits(test_multi_profits_per_episode)\n",
    "\n",
    "print(train_multi_profits.mean(), test_multi_profits.mean())\n",
    "print(train_multi_profits, test_multi_profits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_additive_profits = compute_mean_profits(train_additive_profits_per_episode)\n",
    "test_additive_profits = compute_mean_profits(test_additive_profits_per_episode)\n",
    "\n",
    "print(train_additive_profits, test_additive_profits)\n",
    "print(train_additive_profits.mean(), test_additive_profits.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_rule_based_twb_df)\n",
    "test_rule_based_twb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rule_based_profits = compute_mean_profits(train_rule_based_profits_per_episode)\n",
    "test_rule_based_profits = compute_mean_profits(test_rule_based_profits_per_episode)\n",
    "print(train_rule_based_profits.mean(), test_rule_based_profits.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "greenlight_gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
