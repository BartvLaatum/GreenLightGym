{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from os import path, listdir\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path, data_file):\n",
    "    # load data from csv\n",
    "    df = pd.read_csv(path.join(data_path, data_file))\n",
    "    return df\n",
    "\n",
    "def adjust_time(df):\n",
    "    # compute max fruit harvest\n",
    "    max_fruit_gr = 0.328*1e-6 # kg [DW] m-2 s-1\n",
    "    delta_t = 300\n",
    "    max_fruit_gr *= delta_t\n",
    "    max_fruit_gr\n",
    "\n",
    "    df['Time'] = df['Time'].map(lambda x: str(x)[:-6])\n",
    "    df[\"Fruit harvest norm\"] = df[\"Fruit harvest\"] / max_fruit_gr\n",
    "    df['Date'] = pd.to_datetime(df['Time'])\n",
    "    df['TimeOfDay'] = df['Date'].dt.time\n",
    "    return df\n",
    "\n",
    "def compute_profit_eps(df):\n",
    "    # compute profit per episode\n",
    "    N = (df[df['episode'] == 0]).shape[0]\n",
    "    profits_per_episode = df[['Profits', 'episode']].groupby('episode').sum().reset_index()\n",
    "    return profits_per_episode\n",
    "\n",
    "def extract_data(data_path, last):\n",
    "    runnames = listdir(data_path)\n",
    "    runnames = [runname for runname in runnames if '60' in runname]\n",
    "    if last:\n",
    "        runnames = [runname for runname in runnames if 'last' in runname]\n",
    "    else:\n",
    "        runnames = [runname for runname in runnames if 'best' in runname]\n",
    "\n",
    "    runnames = sorted(runnames, key=lambda x: int(re.findall(r'\\d+', x)[0]))\n",
    "    print(runnames)\n",
    "    # print(runnames)\n",
    "    # sort run on the first integer in their name, use regex\n",
    "    # print(runnames)\n",
    "    \n",
    "    dfs = [load_data(data_path, runname) for runname in runnames]\n",
    "    dfs = [adjust_time(df) for df in dfs]\n",
    "    return dfs, runnames\n",
    "\n",
    "def compute_stats(dfs):\n",
    "    returns = [df['Final return'].unique() for df in dfs]\n",
    "    returns = [np.sort(ret) for ret in returns]\n",
    "    means = np.mean(returns, axis=1)\n",
    "    args = np.argsort(means)[::-1]\n",
    "    quartile1, medians, quartile3 = np.percentile(returns, [25, 50, 75], axis=1)\n",
    "    return quartile1[:], medians[:], quartile3[:], args[:], returns[:]\n",
    "    # returns = [returns[i] for i in args]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def aggregate_data(df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function that computes statistics for violations and profits per episode.\n",
    "    This function takes in a DataFrame and the name of the column to be used for violations.\n",
    "\n",
    "    Args:\n",
    "    - df: the DataFrame\n",
    "    - column: the name of the column to be used for violations\n",
    "\n",
    "    Returns:\n",
    "    - episode: the episode number\n",
    "    - Profits: the total profits for the episode\n",
    "    - CO2 Violation Time (%): the percentage of time with CO2 violations\n",
    "    - CO2 Violation (ppm): the average magnitude of CO2 violations\n",
    "    \"\"\"\n",
    "    # print(df)\n",
    "    N = (df[df['episode'] == 0]).shape[0]\n",
    "    profits_per_episode = df[['Profits', 'episode']].groupby('episode').sum().reset_index()\n",
    "    # CO2 violation time per episode, considering each row as 5 minutes\n",
    "    co2_violation_time_updated = df[df[column] > 0].groupby('episode').size()/N*100 # % of time with violation\n",
    "    # Average magnitude of CO2 violations per episode, for positive violations only\n",
    "    # avg_co2_violation_magnitude_updated = df[[column, 'episode']].groupby('episode')[column].sum()\n",
    "    avg_co2_violation_magnitude_updated = df[df[column] > 0].groupby('episode')[column].mean()\n",
    "    # Combine the updated results into a summary DataFrame\n",
    "    summary_df_updated = pd.DataFrame({\n",
    "        f'Time within boundary (%)': co2_violation_time_updated,\n",
    "        f'{column} (abs)': avg_co2_violation_magnitude_updated,\n",
    "    }).reset_index()\n",
    "\n",
    "\n",
    "    # Create a DataFrame of all unique episodes to ensure all are represented\n",
    "    all_episodes_df = pd.DataFrame(df['episode'].unique(), columns=['episode'])\n",
    "\n",
    "    # Merge the summary of violations with the complete list of episodes\n",
    "    # This ensures episodes with no violations are included, filling missing values appropriately\n",
    "    full_summary_df = pd.merge(all_episodes_df, summary_df_updated, on='episode', how='left').fillna(0)\n",
    "    # print(full_summary_df['coefficients'])\n",
    "    full_summary_df = pd.merge(profits_per_episode, full_summary_df, on='episode', how='left').fillna(0)\n",
    "    full_summary_df['Time within boundary (%)'] = 100- full_summary_df['Time within boundary (%)']\n",
    "    return full_summary_df\n",
    "\n",
    "def calculate_twb(dataframes, labels):\n",
    "    twb_df = pd.DataFrame()\n",
    "    twb_df_ci = pd.DataFrame()\n",
    "    N = dataframes[0]['episode'].unique().shape[0]\n",
    "    for j, df in enumerate(dataframes):\n",
    "        vars = ['CO2 violation', 'Temperature violation', 'Humidity violation']\n",
    "        violations = [aggregate_data(df, var) for var in vars]\n",
    "\n",
    "        twb = np.array([violations[i]['Time within boundary (%)'].mean() for i in range(len(vars))])\n",
    "        df_twb = pd.DataFrame({labels[j]: twb,}, index=vars)\n",
    "        twb_df = pd.concat([twb_df, df_twb], axis=1)\n",
    "        \n",
    "        cis = [ci(violations[i]['Time within boundary (%)'].std(), N) for i in range(len(vars))]\n",
    "        df_twb_ci = pd.DataFrame({labels[j]: cis,}, index=vars)\n",
    "        twb_df_ci = pd.concat([twb_df_ci, df_twb_ci], axis=1)\n",
    "    return twb_df.T, twb_df_ci.T\n",
    "\n",
    "def ci(std, n, z=2.576):\n",
    "    return z*std/np.sqrt(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_profits_twb(path_name):\n",
    "    dfs, runnames = extract_data(path_name, last=True)\n",
    "    # additive_dfs, additive_runnames = extract_data(additive_path, last=True)\n",
    "\n",
    "    profits_per_episode = [compute_profit_eps(df) for df in dfs]\n",
    "    twb_df, twb_df_ci = calculate_twb(dfs, runnames)\n",
    "    return profits_per_episode, twb_df, twb_df_ci, dfs\n",
    "    # additive_profits_per_episode = [compute_profit_eps(df) for df in additive_dfs]\n",
    "    # additive_twb_df, additive_twb_df_ci = calculate_twb(additive_dfs, additive_runnames)\n",
    "\n",
    "\n",
    "def compute_stats(dfs):\n",
    "    returns = [df['Final return'].unique() for df in dfs]\n",
    "    returns = [np.sort(ret) for ret in returns]\n",
    "    means = np.mean(returns, axis=1)\n",
    "    args = np.argsort(means)[::-1]\n",
    "    quartile1, medians, quartile3 = np.percentile(returns, [25, 50, 75], axis=1)\n",
    "    return quartile1[:], medians[:], quartile3[:], args[:], returns[:]\n",
    "    # returns = [returns[i] for i in args]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elegant-carrier-2-60-last.csv', 'rogue-podracer-3-60-last.csv', 'ancient-tie-fighter-4-60-last.csv', 'clean-pyramid-7-60-last.csv', 'sweet-energy-9-60-last.csv']\n",
      "['vibrant-rain-15-60-last.csv', 'trim-dawn-16-60-last.csv', 'vague-breeze-17-60-last.csv', 'cerulean-dawn-19-60-last.csv', 'helpful-sky-20-60-last.csv']\n",
      "['benchmark-60-last.csv']\n"
     ]
    }
   ],
   "source": [
    "multiplicative_path =  '../data/benchmark/test/multiplicative-0.99'\n",
    "additive_path =  '../data/benchmark/test/additive-0.99'\n",
    "rule_based_path =  '../data/benchmark/test/rule-based'\n",
    "\n",
    "test_multi_profits_per_episode, test_multi_twb_df, test_multi_twb_df_ci, test_multi_dfs = compute_profits_twb(multiplicative_path)\n",
    "test_multi_returns = compute_stats(test_multi_dfs)[-1]\n",
    "\n",
    "test_additive_profits_per_episode, test_addtive_twb_df, test_addtive_twb_df_ci, test_additive_dfs = compute_profits_twb(additive_path)\n",
    "test_additive_returns = compute_stats(test_additive_dfs)[-1]\n",
    "\n",
    "test_rule_based_profits_per_episode, test_rule_based_twb_df, test_addtive_twb_df_ci, rule_based_multi_dfs = compute_profits_twb(rule_based_path)\n",
    "# test_rule_based_returns = compute_stats(rule_based_multi_dfs)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data for train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elegant-carrier-2-60-last.csv', 'rogue-podracer-3-60-last.csv', 'ancient-tie-fighter-4-60-last.csv', 'clean-pyramid-7-60-last.csv', 'sweet-energy-9-60-last.csv']\n",
      "['vibrant-rain-15-60-last.csv', 'trim-dawn-16-60-last.csv', 'vague-breeze-17-60-last.csv', 'cerulean-dawn-19-60-last.csv', 'helpful-sky-20-60-last.csv']\n",
      "['benchmark-60-last.csv']\n"
     ]
    }
   ],
   "source": [
    "multiplicative_path =  '../data/benchmark/train/multiplicative-0.99'\n",
    "additive_path =  '../data/benchmark/train/additive-0.99'\n",
    "rule_based_path =  '../data/benchmark/train/rule-based'\n",
    "\n",
    "train_multi_profits_per_episode, train_multi_twb_df, train_multi_twb_df_ci, train_multi_dfs = compute_profits_twb(multiplicative_path)\n",
    "train_multi_returns = compute_stats(train_multi_dfs)[-1]\n",
    "\n",
    "train_additive_profits_per_episode, train_addtive_twb_df, train_addtive_twb_df_ci, train_additive_multi_dfs = compute_profits_twb(additive_path)\n",
    "train_additive_returns = compute_stats(train_additive_multi_dfs)[-1]\n",
    "\n",
    "\n",
    "train_rule_based_profits_per_episode, train_rule_based_twb_df, train_addtive_twb_df_ci, rule_based_multi_dfs = compute_profits_twb(rule_based_path)\n",
    "# train_rule_based_returns = compute_stats(rule_based_multi_dfs)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1665.653486328125, 1635.5689986165364)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_multi_returns), np.mean(test_multi_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1674.56743164, 1706.13344116, 1648.39363403, 1620.81319173,\n",
       "        1678.35973307]),\n",
       " array([1640.0592041 , 1681.73196208, 1621.23024292, 1593.95943604,\n",
       "        1640.86414795]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_multi_returns, axis=1), np.mean(test_multi_returns, axis=\t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CO2 violation            99.518866\n",
       " Temperature violation    98.605440\n",
       " Humidity violation       69.202199\n",
       " dtype: float64,\n",
       " CO2 violation            99.694329\n",
       " Temperature violation    98.688889\n",
       " Humidity violation       68.413773\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_multi_twb_df.mean(), test_multi_twb_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO2 violation</th>\n",
       "      <th>Temperature violation</th>\n",
       "      <th>Humidity violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>elegant-carrier-2-60-last.csv</th>\n",
       "      <td>99.969329</td>\n",
       "      <td>98.523727</td>\n",
       "      <td>71.965278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rogue-podracer-3-60-last.csv</th>\n",
       "      <td>98.868634</td>\n",
       "      <td>99.086806</td>\n",
       "      <td>70.684606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ancient-tie-fighter-4-60-last.csv</th>\n",
       "      <td>99.915509</td>\n",
       "      <td>98.696759</td>\n",
       "      <td>70.225116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean-pyramid-7-60-last.csv</th>\n",
       "      <td>99.977431</td>\n",
       "      <td>97.715856</td>\n",
       "      <td>62.655671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sweet-energy-9-60-last.csv</th>\n",
       "      <td>98.863426</td>\n",
       "      <td>99.004051</td>\n",
       "      <td>70.480324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   CO2 violation  Temperature violation  \\\n",
       "elegant-carrier-2-60-last.csv          99.969329              98.523727   \n",
       "rogue-podracer-3-60-last.csv           98.868634              99.086806   \n",
       "ancient-tie-fighter-4-60-last.csv      99.915509              98.696759   \n",
       "clean-pyramid-7-60-last.csv            99.977431              97.715856   \n",
       "sweet-energy-9-60-last.csv             98.863426              99.004051   \n",
       "\n",
       "                                   Humidity violation  \n",
       "elegant-carrier-2-60-last.csv               71.965278  \n",
       "rogue-podracer-3-60-last.csv                70.684606  \n",
       "ancient-tie-fighter-4-60-last.csv           70.225116  \n",
       "clean-pyramid-7-60-last.csv                 62.655671  \n",
       "sweet-energy-9-60-last.csv                  70.480324  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_multi_twb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1676.5717496744792, 1645.406474609375)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_additive_returns), np.mean(test_additive_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1660.23045044, 1696.46061808, 1679.71027425, 1686.80625   ,\n",
       "        1659.6511556 ]),\n",
       " array([1621.89590047, 1662.97120565, 1652.58707072, 1660.38706258,\n",
       "        1629.19113363]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_additive_returns, axis=1), np.mean(test_additive_returns, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CO2 violation            99.656250\n",
       " Temperature violation    99.623264\n",
       " Humidity violation       87.717477\n",
       " dtype: float64,\n",
       " CO2 violation            99.706944\n",
       " Temperature violation    99.675926\n",
       " Humidity violation       88.240856\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_addtive_twb_df.mean(), test_addtive_twb_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                              CO2 violation  Temperature violation  \\\n",
       " vibrant-rain-15-60-last.csv      100.000000              99.699653   \n",
       " trim-dawn-16-60-last.csv          99.525463              99.489583   \n",
       " vague-breeze-17-60-last.csv       99.692130              99.652199   \n",
       " cerulean-dawn-19-60-last.csv      99.373843              99.564236   \n",
       " helpful-sky-20-60-last.csv        99.689815              99.710648   \n",
       " \n",
       "                               Humidity violation  \n",
       " vibrant-rain-15-60-last.csv            89.552662  \n",
       " trim-dawn-16-60-last.csv               89.576389  \n",
       " vague-breeze-17-60-last.csv            88.247685  \n",
       " cerulean-dawn-19-60-last.csv           84.914352  \n",
       " helpful-sky-20-60-last.csv             86.296296  ,\n",
       "                               CO2 violation  Temperature violation  \\\n",
       " vibrant-rain-15-60-last.csv      100.000000              99.865162   \n",
       " trim-dawn-16-60-last.csv          99.737847              99.454282   \n",
       " vague-breeze-17-60-last.csv       99.733796              99.791088   \n",
       " cerulean-dawn-19-60-last.csv      99.302083              99.612847   \n",
       " helpful-sky-20-60-last.csv        99.760995              99.656250   \n",
       " \n",
       "                               Humidity violation  \n",
       " vibrant-rain-15-60-last.csv            89.534144  \n",
       " trim-dawn-16-60-last.csv               89.866319  \n",
       " vague-breeze-17-60-last.csv            89.810764  \n",
       " cerulean-dawn-19-60-last.csv           85.628472  \n",
       " helpful-sky-20-60-last.csv             86.364583  )"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_addtive_twb_df, test_addtive_twb_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8818851200703164 3.7879600670529237\n",
      "[3.89222694 3.98844503 3.80042264 3.84705111 3.88127987] [3.80814382 3.9075376  3.70826994 3.74682173 3.76902725]\n"
     ]
    }
   ],
   "source": [
    "def compute_mean_profits(profits_per_episode):\n",
    "    return np.array([df.mean()['Profits'] for df in profits_per_episode])\n",
    "\n",
    "train_multi_profits = compute_mean_profits(train_multi_profits_per_episode)\n",
    "test_multi_profits = compute_mean_profits(test_multi_profits_per_episode)\n",
    "\n",
    "print(train_multi_profits.mean(), test_multi_profits.mean())\n",
    "print(train_multi_profits, test_multi_profits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.70083208 3.81797977 3.76203187 3.8390939  3.7147926 ] [3.57849703 3.7053569  3.65816119 3.74262091 3.61560591]\n",
      "3.766946045159885 3.660048387292508\n"
     ]
    }
   ],
   "source": [
    "train_additive_profits = compute_mean_profits(train_additive_profits_per_episode)\n",
    "test_additive_profits = compute_mean_profits(test_additive_profits_per_episode)\n",
    "\n",
    "print(train_additive_profits, test_additive_profits)\n",
    "print(train_additive_profits.mean(), test_additive_profits.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       CO2 violation  Temperature violation  \\\n",
      "benchmark-60-last.csv       99.89294              99.904514   \n",
      "\n",
      "                       Humidity violation  \n",
      "benchmark-60-last.csv           83.077546  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO2 violation</th>\n",
       "      <th>Temperature violation</th>\n",
       "      <th>Humidity violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>benchmark-60-last.csv</th>\n",
       "      <td>99.938657</td>\n",
       "      <td>99.956308</td>\n",
       "      <td>84.099826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       CO2 violation  Temperature violation  \\\n",
       "benchmark-60-last.csv      99.938657              99.956308   \n",
       "\n",
       "                       Humidity violation  \n",
       "benchmark-60-last.csv           84.099826  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_rule_based_twb_df)\n",
    "test_rule_based_twb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9712523569443565 3.9023978349604183\n"
     ]
    }
   ],
   "source": [
    "train_rule_based_profits = compute_mean_profits(train_rule_based_profits_per_episode)\n",
    "test_rule_based_profits = compute_mean_profits(test_rule_based_profits_per_episode)\n",
    "print(train_rule_based_profits.mean(), test_rule_based_profits.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "greenlight_gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
