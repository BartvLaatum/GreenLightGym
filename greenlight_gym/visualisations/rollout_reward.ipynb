{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting episode return during training\n",
    "\n",
    "This notebook generates plots to evaluate the data generated during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cmcrameri.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from os import path, listdir\n",
    "from scipy.stats import normaltest, kruskal, mannwhitneyu\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from greenlight_gym.visualisations.utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arc_pen(x, ki:float):\n",
    "    return np.arctan(x*ki)\n",
    "\n",
    "def load_data(data_path, data_file):\n",
    "    # load data from csv\n",
    "    df = pd.read_csv(path.join(data_path, data_file))\n",
    "    return df\n",
    "\n",
    "def compute_profit_eps(df):\n",
    "    # compute profit per episode\n",
    "    N = (df[df['episode'] == 0]).shape[0]\n",
    "    profits_per_episode = df[['Profits', 'episode']].groupby('episode').sum().reset_index()\n",
    "    return profits_per_episode\n",
    "\n",
    "\n",
    "def compute_constraints(df: pd.DataFrame, column: str, ki: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function that computes statistics for violations and profits per episode.\n",
    "    This function takes in a DataFrame and the name of the column to be used for violations.\n",
    "\n",
    "    Args:\n",
    "    - df: the DataFrame\n",
    "    - column: the name of the column to be used for violations\n",
    "\n",
    "    Returns:\n",
    "    - episode: the episode number\n",
    "    - Profits: the total profits for the episode\n",
    "    - CO2 Violation Time (%): the percentage of time with CO2 violations\n",
    "    - CO2 Violation (ppm): the average magnitude of CO2 violations\n",
    "    \"\"\"\n",
    "    # print(df)\n",
    "    N = (df[df['episode'] == 0]).shape[0]\n",
    "    # profits_per_episode = df[['Profits', 'episode']].groupby('episode').sum().reset_index()\n",
    "    # CO2 violation time per episode, considering each row as 5 minutes\n",
    "\n",
    "    df['penalty score'] = df[column].apply(arc_pen, args=(ki,))\n",
    "\n",
    "    penalty_score = df.groupby('episode')['penalty score'].sum()\n",
    "    # Combine the updated results into a summary DataFrame\n",
    "\n",
    "    summary_df_updated = pd.DataFrame({\n",
    "        f'Penalty scores': penalty_score,\n",
    "        # f'{column} (abs)': avg_co2_violation_magnitude_updated,\n",
    "    }).reset_index()\n",
    "\n",
    "    return summary_df_updated\n",
    "\n",
    "def aggregate_data(df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function that computes statistics for violations and profits per episode.\n",
    "    This function takes in a DataFrame and the name of the column to be used for violations.\n",
    "\n",
    "    Args:\n",
    "    - df: the DataFrame\n",
    "    - column: the name of the column to be used for violations\n",
    "\n",
    "    Returns:\n",
    "    - episode: the episode number\n",
    "    - Profits: the total profits for the episode\n",
    "    - CO2 Violation Time (%): the percentage of time with CO2 violations\n",
    "    - CO2 Violation (ppm): the average magnitude of CO2 violations\n",
    "    \"\"\"\n",
    "    # print(df)\n",
    "    N = (df[df['episode'] == 0]).shape[0]\n",
    "    profits_per_episode = df[['Profits', 'episode']].groupby('episode').sum().reset_index()\n",
    "    # CO2 violation time per episode, considering each row as 5 minutes\n",
    "    co2_violation_time_updated = df[df[column] > 0].groupby('episode').size()/N*100 # % of time with violation\n",
    "    # Average magnitude of CO2 violations per episode, for positive violations only\n",
    "    # avg_co2_violation_magnitude_updated = df[[column, 'episode']].groupby('episode')[column].sum()\n",
    "    avg_co2_violation_magnitude_updated = df[df[column] > 0].groupby('episode')[column].mean()\n",
    "    # Combine the updated results into a summary DataFrame\n",
    "    summary_df_updated = pd.DataFrame({\n",
    "        f'Time within boundary (%)': co2_violation_time_updated,\n",
    "        f'{column} (abs)': avg_co2_violation_magnitude_updated,\n",
    "    }).reset_index()\n",
    "\n",
    "\n",
    "    # Create a DataFrame of all unique episodes to ensure all are represented\n",
    "    all_episodes_df = pd.DataFrame(df['episode'].unique(), columns=['episode'])\n",
    "\n",
    "    # Merge the summary of violations with the complete list of episodes\n",
    "    # This ensures episodes with no violations are included, filling missing values appropriately\n",
    "    full_summary_df = pd.merge(all_episodes_df, summary_df_updated, on='episode', how='left').fillna(0)\n",
    "    # print(full_summary_df['coefficients'])\n",
    "    full_summary_df = pd.merge(profits_per_episode, full_summary_df, on='episode', how='left').fillna(0)\n",
    "    full_summary_df['Time within boundary (%)'] = 100- full_summary_df['Time within boundary (%)']\n",
    "    return full_summary_df\n",
    "\n",
    "def calculate_twb(dataframes, labels):\n",
    "    twb_df = pd.DataFrame()\n",
    "    twb_df_ci = pd.DataFrame()\n",
    "    N = dataframes[0]['episode'].unique().shape[0]\n",
    "    for j, df in enumerate(dataframes):\n",
    "        vars = ['CO2 violation', 'Temperature violation', 'Humidity violation']\n",
    "        violations = [aggregate_data(df, var) for var in vars]\n",
    "\n",
    "        twb = np.array([violations[i]['Time within boundary (%)'].mean() for i in range(len(vars))])\n",
    "        df_twb = pd.DataFrame({labels[j]: twb,}, index=vars)\n",
    "        twb_df = pd.concat([twb_df, df_twb], axis=1)\n",
    "        \n",
    "        cis = [ci(violations[i]['Time within boundary (%)'].std(), N) for i in range(len(vars))]\n",
    "        df_twb_ci = pd.DataFrame({labels[j]: cis,}, index=vars)\n",
    "        twb_df_ci = pd.concat([twb_df_ci, df_twb_ci], axis=1)\n",
    "    return twb_df.T, twb_df_ci.T\n",
    "\n",
    "\n",
    "def calculate_tan(dataframes, labels, ks):\n",
    "    twb_df = pd.DataFrame()\n",
    "    twb_df_ci = pd.DataFrame()\n",
    "    N = dataframes[0]['episode'].unique().shape[0]\n",
    "    vars = ['CO2 violation', 'Temperature violation', 'Humidity violation']\n",
    "    for j, df in enumerate(dataframes):\n",
    "        violations = [compute_constraints(df, var, ks[i]) for i, var in enumerate(vars)]\n",
    "\n",
    "        twb = np.array([violations[i]['Penalty scores'].mean() for i in range(len(vars))])\n",
    "        df_twb = pd.DataFrame({labels[j]: twb,}, index=vars)\n",
    "        twb_df = pd.concat([twb_df, df_twb], axis=1)\n",
    "\n",
    "        cis = [ci(violations[i]['Penalty scores'].std(), N) for i in range(len(vars))]\n",
    "        df_twb_ci = pd.DataFrame({labels[j]: cis,}, index=vars)\n",
    "        twb_df_ci = pd.concat([twb_df_ci, df_twb_ci], axis=1)\n",
    "    return twb_df.T, twb_df_ci.T\n",
    "\n",
    "def ci(std, n, z=2.576):\n",
    "    return z*std/np.sqrt(n)\n",
    "\n",
    "def adjust_time(df):\n",
    "    # compute max fruit harvest\n",
    "    max_fruit_gr = 0.328*1e-6 # kg [DW] m-2 s-1\n",
    "    delta_t = 300\n",
    "    max_fruit_gr *= delta_t\n",
    "    max_fruit_gr\n",
    "\n",
    "    df['Time'] = df['Time'].map(lambda x: str(x)[:-6])\n",
    "    df[\"Fruit harvest norm\"] = df[\"Fruit harvest\"] / max_fruit_gr\n",
    "    df['Date'] = pd.to_datetime(df['Time'])\n",
    "    df['TimeOfDay'] = df['Date'].dt.time\n",
    "    return df\n",
    "\n",
    "def plot_avg_day(df, variable, fig, ax, label, linestyle, color):\n",
    "    time_step_means = df.groupby('TimeOfDay')[variable].mean().reset_index()\n",
    "    # time_step_means = df.groupby('TimeOfDay')[variable].std().reset_index()\n",
    "\n",
    "    # Convert 'TimeOfDay' to minutes past midnight for plotting\n",
    "    time_step_means['MinutesPastMidnight'] = time_step_means['TimeOfDay'].apply(lambda t: t.hour + t.minute/60)\n",
    "\n",
    "    # Plotting with the modified time format\n",
    "    ax.plot(time_step_means['MinutesPastMidnight'], time_step_means[variable], linestyle=linestyle, linewidth=4, color=color, label=label)\n",
    "    # ax.title('Average Temperature per Time Step Across All Runs')\n",
    "    ax.set_xlabel('Hour of the day')\n",
    "    ax.set_ylabel(variable)\n",
    "    ax.set_xticks(np.arange(0, 25, 6))\n",
    "    return fig, ax\n",
    "\n",
    "def plot_avg_state(dataframes, labels, variables, colors):\n",
    "    # nrows = len\n",
    "    fig, axes = plt.subplots(1,len(variables), figsize =(16, 8), dpi=120)\n",
    "    # colors = [cm.tokyoS(4+i) for i in range(len(dataframes))]\n",
    "    for j, df in enumerate(dataframes):\n",
    "        \n",
    "        for i, ax in enumerate(axes):\n",
    "            plot_avg_day(df, variables[i], fig, ax, labels[j], linestyle='-', color=colors[j])\n",
    "\n",
    "    # Create the legend\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    # Adjust the layout to make space for the legend\n",
    "    plt.subplots_adjust(right=0.8)\n",
    "\n",
    "    # Show the plot\n",
    "    # plt.show()\n",
    "        \n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def generate_barplots(dataframes, xlabels, colors):\n",
    "    fig, ax = plt.subplots(dpi=120)\n",
    "    n = dataframes[0][0].shape[0]  # Assuming all dataframes have the same shape\n",
    "    # print(n)\n",
    "    # colors = [cm.tokyoS(4+i) for i in range(len(dataframes))]\n",
    "    \n",
    "    \n",
    "    for i, dataframe in enumerate(dataframes):\n",
    "        heights = []\n",
    "        errors = []\n",
    "        bar_width = 0.3\n",
    "\n",
    "        for j, df in enumerate(dataframe):\n",
    "            heights.append(df['Profits'].mean())\n",
    "            errors.append(ci(df['Profits'].std(), n))\n",
    "        print(len(heights), len(errors), len(xlabels))\n",
    "        if i ==0:\n",
    "            ax.bar(xlabels-bar_width/2, heights, width=bar_width, color=colors[i], edgecolor='black')\n",
    "            ax.errorbar(xlabels-bar_width/2, heights, yerr=errors, capsize=5, linestyle='None', color='black', fmt='')\n",
    "    \n",
    "        else:\n",
    "            ax.bar(xlabels+bar_width/2, heights, width=bar_width, color=colors[i], edgecolor='black')\n",
    "            ax.errorbar(xlabels+bar_width/2, heights, yerr=errors, capsize=5, linestyle='None', color='black', fmt='')\n",
    "    # print(heights, errors)\n",
    "\n",
    "    ax.set_xlabel('Random seed')\n",
    "    ax.set_ylabel(r'$r_{0:N}^{\\mathrm{profit}}$')\n",
    "\n",
    "    ax.set_xticks(xlabels)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('profits-per-seed-2.svg')\n",
    "    plt.show()\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_grouped_bar_plot(twb_df, twb_df_ci, xlabels):\n",
    "    co2color = cm.tokyoS(4)\n",
    "    tcolor = cm.tokyoS(5)\n",
    "    humcolor = cm.tokyoS(6)\n",
    "\n",
    "    fig, ax = plt.subplots(dpi=120)\n",
    "\n",
    "    index = np.arange(len(xlabels))\n",
    "\n",
    "    bar_width = 0.2\n",
    "\n",
    "    bars1 = ax.bar(index - bar_width, twb_df['CO2 violation'], bar_width, edgecolor='black', color=co2color, label=r'CO$_2$')\n",
    "    ax.errorbar(index - bar_width, twb_df['CO2 violation'], yerr=twb_df_ci[\"CO2 violation\"], capsize=5, linestyle='None', color='black', fmt='')\n",
    "\n",
    "    bars2 = ax.bar(index, twb_df['Temperature violation'], bar_width, edgecolor='black', color=tcolor, label='Temperature')\n",
    "    ax.errorbar(index, twb_df['Temperature violation'], yerr=twb_df_ci[\"Temperature violation\"], capsize=5, linestyle='None', color='black', fmt='')\n",
    "\n",
    "    bars3 = ax.bar(index + bar_width, twb_df['Humidity violation'], bar_width, edgecolor='black', color=humcolor, label='Humidity')\n",
    "    ax.errorbar(index + bar_width, twb_df['Humidity violation'], yerr=twb_df_ci[\"Humidity violation\"], capsize=5, linestyle='None', color='black', fmt='')\n",
    "\n",
    "    ax.set_xticks(index)\n",
    "    ax.set_xticklabels(xlabels)\n",
    "    ax.set_xlabel('Random seed')\n",
    "    ax.set_ylabel('TWB (%)')\n",
    "    ax.legend()\n",
    "    # ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('twb-seeds.svg')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def generate_grouped_bar_plot2(twb_df1, twb_df_ci1, twb_df2, twb_df_ci2, xlabels):\n",
    "    additive_color = cm.tokyoS(4)\n",
    "    multiplicative_color = cm.tokyoS(6)\n",
    "\n",
    "    fig, ax = plt.subplots(dpi=120)\n",
    "    index = np.arange(len(xlabels))\n",
    "    bar_width = 0.15\n",
    "    \n",
    "    # Controller 1\n",
    "    bars1_1 = ax.bar(index - 2.5*bar_width, twb_df1['CO2 violation'], bar_width, edgecolor='black', color=additive_color, label=r'CO$_2$', hatch='//')\n",
    "    bars1_1 = ax.bar(index - 2.5*bar_width, twb_df1['CO2 violation'], bar_width, edgecolor='black',color='none', label=r'CO$_2$')\n",
    "    ax.errorbar(index - 2.5*bar_width, twb_df1['CO2 violation'], yerr=twb_df_ci1[\"CO2 violation\"], capsize=5, linestyle='None', color='black', fmt='')\n",
    "\n",
    "    bars1_2 = ax.bar(index - 0.5*bar_width, twb_df1['Temperature violation'], bar_width, edgecolor='black', color=additive_color, label='Temperature', hatch=\"\\\\\\\\\")\n",
    "    bars1_2 = ax.bar(index - 0.5*bar_width, twb_df1['Temperature violation'], bar_width, edgecolor='black', color='none', label='Temperature')\n",
    "    ax.errorbar(index - 0.5*bar_width, twb_df1['Temperature violation'], yerr=twb_df_ci1[\"Temperature violation\"], capsize=5, linestyle='None', color='black', fmt='')\n",
    "\n",
    "    bars1_3 = ax.bar(index + 1.5*bar_width, twb_df1['Humidity violation'], bar_width, edgecolor='black', color=additive_color, label='Humidity (Controller 1)', hatch='xx')\n",
    "    bars1_3 = ax.bar(index + 1.5*bar_width, twb_df1['Humidity violation'], bar_width, edgecolor='black', color='none', label='Humidity')\n",
    "    ax.errorbar(index + 1.5*bar_width, twb_df1['Humidity violation'], yerr=twb_df_ci1[\"Humidity violation\"], capsize=5, linestyle='None', color='black', fmt='')\n",
    "\n",
    "    # Controller 2\n",
    "    bars2_1 = ax.bar(index - 1.5*bar_width, twb_df2['CO2 violation'], bar_width, edgecolor='black', color=multiplicative_color, label=r'CO$_2$', hatch='//')\n",
    "    bars2_1 = ax.bar(index - 1.5*bar_width, twb_df2['CO2 violation'], bar_width, edgecolor='black', color='none', label=r'CO$_2$')\n",
    "    ax.errorbar(index - 1.5*bar_width, twb_df2['CO2 violation'], yerr=twb_df_ci2[\"CO2 violation\"], capsize=5, linestyle='None', color='black', fmt='')\n",
    "\n",
    "    bars2_2 = ax.bar(index + 0.5*bar_width, twb_df2['Temperature violation'], bar_width, edgecolor='black', color=multiplicative_color, label='Temperature (Controller 2)', hatch='\\\\\\\\')\n",
    "    bars2_1 = ax.bar(index + 0.5*bar_width, twb_df2['Temperature violation'], bar_width, edgecolor='black', color='none', label='Temperature')\n",
    "    ax.errorbar(index+ 0.5*bar_width, twb_df2['Temperature violation'], yerr=twb_df_ci2[\"Temperature violation\"], capsize=5, linestyle='None', color='black', fmt='')\n",
    "\n",
    "    bars2_3 = ax.bar(index + 2.5*bar_width, twb_df2['Humidity violation'], bar_width, edgecolor='black', color=multiplicative_color, label='Humidity (Controller 2)', hatch='xx')\n",
    "    bars2_3 = ax.bar(index + 2.5*bar_width, twb_df2['Humidity violation'], bar_width, edgecolor='black', color='none', label='Humidity')\n",
    "    ax.errorbar(index + 2.5*bar_width, twb_df2['Humidity violation'], yerr=twb_df_ci2[\"Humidity violation\"], capsize=5, linestyle='None', color='black', fmt='')\n",
    "\n",
    "    # Create custom patches for hatches\n",
    "    hatch_CO2 = mpatches.Patch(facecolor='white', edgecolor='black', hatch='//', label=r'CO$_2$')\n",
    "    hatch_Temperature = mpatches.Patch(facecolor='white', edgecolor='black', hatch='\\\\\\\\', label='Temperature')\n",
    "    hatch_Humidity = mpatches.Patch(facecolor='white', edgecolor='black', hatch='xx', label='Humidity')\n",
    "\n",
    "    ax.legend(handles=[hatch_CO2, hatch_Temperature, hatch_Humidity])\n",
    "\n",
    "    ax.set_xticks(index)\n",
    "    ax.set_xticklabels(xlabels)\n",
    "    ax.set_xlabel('Random seed')\n",
    "    ax.set_ylabel('TWB (%)')\n",
    "    # ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('twb-seeds-comparison.svg', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Latex font in plots\n",
    "plt.rcParams['font.serif'] = \"cmr10\"\n",
    "plt.rcParams['font.family'] = \"serif\"\n",
    "plt.rcParams['font.size'] = 24\n",
    "\n",
    "plt.rcParams['legend.fontsize'] = 24\n",
    "plt.rcParams['legend.loc'] = 'upper right'\n",
    "plt.rcParams['axes.labelsize'] = 24\n",
    "plt.rcParams['axes.formatter.use_mathtext'] = True\n",
    "plt.rcParams['xtick.labelsize'] = 24\n",
    "plt.rcParams['ytick.labelsize'] = 24\n",
    "plt.rcParams['text.usetex'] = False\n",
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "plt.rcParams['axes.linewidth'] = 4   # Default for all spines\n",
    "# plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['lines.linewidth'] = 3\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['xtick.major.size'] = 6  # Thicker major x-ticks\n",
    "plt.rcParams['xtick.major.width'] = 2  # Thicker major x-\n",
    "plt.rcParams['ytick.major.size'] = 6  \n",
    "plt.rcParams['ytick.major.width'] = 2 \n",
    "plt.rc('axes', unicode_minus=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_ticks(x, pos):\n",
    "    return f'{x * 1e-6}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths =  ['../data/benchmark/train/additive-0.99', '../data/benchmark/train/multiplicative-0.99']\n",
    "data_file = 'rollout.csv'\n",
    "dfs = [load_data(data_path, data_file) for data_path in data_paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(dfs, rolling_window_size=1):\n",
    "    seeds_dfs = []\n",
    "    for df in dfs:\n",
    "        mean_seeds = df.groupby('global step')['train reward'].mean().rolling(rolling_window_size).mean()\n",
    "        std_seeds = df.groupby('global step')['train reward'].std()\n",
    "\n",
    "        # interpolate the missing values\n",
    "        std_seeds = std_seeds.interpolate().rolling(rolling_window_size).mean()\n",
    "        seeds_df = pd.DataFrame({'std': std_seeds, 'mean': mean_seeds})\n",
    "        seeds_dfs.append(seeds_df)\n",
    "    return seeds_dfs\n",
    "\n",
    "def plot_learning_curve(seeds_dfs, labels, colors):\n",
    "\n",
    "    fig, ax = plt.subplots(dpi=120)\n",
    "    for i, seeds_df in enumerate(seeds_dfs):\n",
    "\n",
    "        ax.plot(seeds_df.index, seeds_df['mean'], color=colors[i], label=labels[i])\n",
    "        ax.fill_between(seeds_df.index, seeds_df['mean'] - seeds_df['std'], seeds_df['mean'] + seeds_df['std'], color=colors[i], alpha=0.3)\n",
    "\n",
    "    ax.set_xlabel('Time steps (millions)')\n",
    "    ax.set_ylabel('Average return')\n",
    "    # ax.legend()\n",
    "    ax.set_xscale('log')\n",
    "    # ax.set_xticks(np.round(np.linspace(0, 4e7, 5), 0))\n",
    "    ax.set_yticks(np.round(np.linspace(1200, 1650, 4), 0))\n",
    "    ax.ticklabel_format(axis='y', style='sci', scilimits=(3,3))\n",
    "\n",
    "    formatter = FuncFormatter(format_ticks)\n",
    "    #  plt.locator_params(axis='both', nbins=4) \n",
    "    # For x-axis\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('convergence-seeds-xlog.svg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [cm.tokyoS(4), cm.tokyoS(6)]\n",
    "labels = ['Additive reward', 'Multiplicative reward']\n",
    "seeds_dfs = compute_stats(dfs, rolling_window_size=10)\n",
    "plot_learning_curve(seeds_dfs, labels, colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentual difference between 1607 and 1629\n",
    "initial_value = 1607\n",
    "final_value = 1629\n",
    "\n",
    "def percentual_difference(initial_value, final_value):\n",
    "    return ((final_value - initial_value) / initial_value) * 100\n",
    "\n",
    "delta = ((final_value - initial_value) / initial_value) * 100\n",
    "delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_dfs[0]['mean'], seeds_dfs[1]['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = percentual_difference(seeds_dfs[0]['mean'], seeds_dfs[1]['mean'])\n",
    "\n",
    "# interpolate the missing values\n",
    "delta = delta.interpolate().rolling(10).mean()\n",
    "\n",
    "fig, ax = plt.subplots(dpi=120)\n",
    "ax.plot(delta, color=cm.tokyoS(2))\n",
    "ax.set_xlabel('Time steps (millions)')\n",
    "ax.set_ylabel(r'$\\Delta \\%$')\n",
    "ax.set_xscale('log')\n",
    "fig.tight_layout()\n",
    "# fig.savefig('convergence-seeds-difference-xlog.svg')\n",
    "plt.show()\n",
    "\n",
    "delta[delta.index >10e6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(501).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [cm.tokyoS(4), cm.tokyoS(6)]\n",
    "convergence_rate_1 = np.gradient(seeds_dfs[0]['mean'], seeds_dfs[0].index)\n",
    "convergence_rate_2 = np.gradient(seeds_dfs[1]['mean'], seeds_dfs[1].index)\n",
    "\n",
    "def moving_average(data, window_size):\n",
    "    return np.convolve(data, np.ones(window_size) / window_size, mode='valid')\n",
    "\n",
    "window_size =10\n",
    "\n",
    "smoothed_rate_1 = moving_average(convergence_rate_1, window_size=window_size)\n",
    "smoothed_rate_2 = moving_average(convergence_rate_2, window_size=window_size)\n",
    "\n",
    "fig, ax = plt.subplots(dpi=120)\n",
    "ax.plot(seeds_dfs[0].index[window_size-1:], smoothed_rate_1,color=colors[0], label='Additive reward')\n",
    "ax.plot(seeds_dfs[1].index[window_size-1:], smoothed_rate_2, color=colors[1],label='Multiplicative reward', linestyle='--')\n",
    "\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_xticks(np.round(np.linspace(0, 4e7, 5), 0))\n",
    "formatter = FuncFormatter(format_ticks)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "ax.set_xlabel('Time steps (millions)')\n",
    "ax.set_ylabel('Convergence rate')\n",
    "ax.ticklabel_format(axis='y', style='sci', scilimits=(-3,-3))\n",
    "# ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('convergence-rate-xlog.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [cm.tokyoS(4), cm.tokyoS(6)]\n",
    "cv_loss_1 = seeds_dfs[0]['std'] /seeds_dfs[0]['mean']\n",
    "cv_loss_2 = seeds_dfs[1]['std'] / seeds_dfs[1]['mean']\n",
    "\n",
    "fig, ax = plt.subplots(dpi=120)\n",
    "\n",
    "smoothened_cv_1 = moving_average(cv_loss_1, window_size=window_size)\n",
    "smoothened_cv_2 = moving_average(cv_loss_2, window_size=window_size)\n",
    "\n",
    "ax.plot(seeds_dfs[0].index[window_size-1:],smoothened_cv_1, color=colors[0], label='Additive reward')\n",
    "ax.plot(seeds_dfs[1].index[window_size-1:], smoothened_cv_2, color=colors[1],  label='Multiplicative reward')\n",
    "\n",
    "# ax.set_xticks(np.round(np.linspace(0, 4e7, 5), 0))\n",
    "formatter = FuncFormatter(format_ticks)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "ax.set_xlabel('Time steps (millions)')\n",
    "ax.set_ylabel(r'CV $(\\sigma/\\mu)$')\n",
    "ax.set_xscale('log')\n",
    "fig.tight_layout()\n",
    "fig.savefig('CV-xlog.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising return distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_data(data_path, last):\n",
    "    runnames = listdir(data_path)\n",
    "    runnames = [runname for runname in runnames if '60' in runname]\n",
    "    if last:\n",
    "        print(runnames)\n",
    "        runnames = [runname for runname in runnames if 'last' in runname]\n",
    "    else:\n",
    "        runnames = [runname for runname in runnames if 'best' in runname]\n",
    "\n",
    "    runnames = sorted(runnames, key=lambda x: int(re.findall(r'\\d+', x)[0]))\n",
    "    print(runnames)\n",
    "    # print(runnames)\n",
    "    # sort run on the first integer in their name, use regex\n",
    "    # print(runnames)\n",
    "    \n",
    "    dfs = [load_data(data_path, runname) for runname in runnames]\n",
    "    dfs = [adjust_time(df) for df in dfs]\n",
    "    return dfs, runnames\n",
    "\n",
    "def compute_stats(dfs):\n",
    "    returns = [df['Final return'].unique() for df in dfs]\n",
    "    returns = [np.sort(ret) for ret in returns]\n",
    "    means = np.mean(returns, axis=1)\n",
    "    args = np.argsort(means)[::-1]\n",
    "    quartile1, medians, quartile3 = np.percentile(returns, [25, 50, 75], axis=1)\n",
    "    return quartile1[:], medians[:], quartile3[:], args[:], returns[:]\n",
    "    # returns = [returns[i] for i in args]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplicative_path =  '../data/benchmark/train/multiplicative-0.99'\n",
    "additive_path =  '../data/benchmark/train/additive-0.99'\n",
    "\n",
    "multi_dfs, multi_runnames = extract_data(multiplicative_path, last=True)\n",
    "additive_dfs, additive_runnames = extract_data(additive_path, last=True)\n",
    "\n",
    "print(multi_runnames)\n",
    "\n",
    "multi_profits_per_episode = [compute_profit_eps(df) for df in multi_dfs]\n",
    "multi_twb_df, multi_twb_df_ci = calculate_twb(multi_dfs, multi_runnames)\n",
    "additive_profits_per_episode = [compute_profit_eps(df) for df in additive_dfs]\n",
    "additive_twb_df, additive_twb_df_ci = calculate_twb(additive_dfs, additive_runnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additive_stats = compute_stats(additive_dfs)\n",
    "multi_stats = compute_stats(multi_dfs)\n",
    "stats = [additive_stats, multi_stats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacent_values(vals, q1, q3):\n",
    "    upper_adjacent_value = q3 + (q3 - q1) * 1.5\n",
    "    upper_adjacent_value = np.clip(upper_adjacent_value, q3, vals[-1])\n",
    "    lower_adjacent_value = q1 - (q3 - q1) * 1.5\n",
    "    lower_adjacent_value = np.clip(lower_adjacent_value, vals[0], q1)\n",
    "    return lower_adjacent_value, upper_adjacent_value\n",
    "\n",
    "def plot_grouped_violin(stats, colors):\n",
    "    fig, ax = plt.subplots(dpi=120)\n",
    "\n",
    "    # Assuming stats is a list with two lists\n",
    "    num_groups = len(stats[0][1])\n",
    "    positions = np.arange(1, num_groups + 1)\n",
    "    width = 0.3\n",
    "    print(num_groups)\n",
    "    for s, stat in enumerate(stats):\n",
    "        quartile1, medians, quartile3, args, returns = stat\n",
    "\n",
    "        # Offset the positions for each distribution\n",
    "        pos = positions + width * (s - 0.5)\n",
    "\n",
    "        parts = ax.violinplot(returns, positions=pos, widths=width,\n",
    "                                showmeans=False, showmedians=False, showextrema=False)\n",
    "\n",
    "        for i, pc in enumerate(parts['bodies']):\n",
    "            pc.set_facecolor(colors[s])\n",
    "            pc.set_edgecolor('black')\n",
    "            pc.set_alpha(0.9)\n",
    "\n",
    "        whiskers = np.array([\n",
    "            adjacent_values(sorted_array, q1, q3)\n",
    "            for sorted_array, q1, q3 in zip(returns, quartile1, quartile3)\n",
    "        ])\n",
    "        whiskers_min, whiskers_max = whiskers[:, 0], whiskers[:, 1]\n",
    "        ax.scatter(pos, medians, marker='o', color='white', s=30, zorder=3)\n",
    "        ax.vlines(pos, quartile1, quartile3, color='k', linestyle='-', lw=5)\n",
    "        ax.vlines(pos, whiskers_min, whiskers_max, color='k', linestyle='-', lw=2)\n",
    "\n",
    "    ax.set_xticks(positions)\n",
    "    ax.set_xticklabels(positions)\n",
    "    ax.set_yticks(np.round(np.linspace(1250, 2000, 4), 0))\n",
    "    ax.ticklabel_format(axis='y', style='sci', scilimits=(3,3))\n",
    "    ax.set_xlabel('Random seed')\n",
    "    ax.set_ylabel('Episodic return')\n",
    "\n",
    "    ax.legend([plt.Rectangle((0,0),1,1,fc=colors[0]), \n",
    "                plt.Rectangle((0,0),1,1,fc=colors[1])],\n",
    "                ['Additive reward', 'Multiplicative reward'], loc='upper right')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('episodic-return-violin.svg')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grouped_violin(stats, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test whether the distribution comes from normal distribution\n",
    "\n",
    "If $p<0.05$ than we reject the null-hypothesis that the sample comes from a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_test(returns):\n",
    "    for ret in returns[:]:\n",
    "        res = normaltest(ret)\n",
    "        print(res.statistic, res.pvalue)\n",
    "\n",
    "def display_stats(returns):\n",
    "    for ret in returns:\n",
    "        print(ret.mean(), np.median(ret), ret.std())\n",
    "\n",
    "print(\"additive:\")\n",
    "norm_test(stats[0][-1])\n",
    "print(\"multiplicative:\")\n",
    "norm_test(stats[1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"additive:\")\n",
    "display_stats(stats[0][-1])\n",
    "print(\"multiplicative:\")\n",
    "display_stats(stats[1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_returns(returns, SEEDS):\n",
    "    results = []\n",
    "\n",
    "    for i, ret in enumerate(returns):\n",
    "        for j, ret2 in enumerate(returns[i:]):\n",
    "            j += i\n",
    "            result = {\n",
    "                'Seed 1': SEEDS[i],\n",
    "                'Seed 2': SEEDS[j],\n",
    "                'Mann-Whitney U': mannwhitneyu(ret, ret2).statistic,\n",
    "                'p-value': mannwhitneyu(ret, ret2).pvalue\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analyze_returns(stats[0][-1], additive_runnames)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analyze_returns(stats[1][-1], multi_runnames)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kruskal(stats[0][-1])\n",
    "kruskal(*stats[0][-1]), kruskal(*stats[1][-1]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors= [cm.tokyoS(i) for i in range(4, 4+len(additive_runnames))]\n",
    "colors = [cm.tokyoS(4), cm.tokyoS(6)]\n",
    "# random_seeds = np.arange(len(runnames))\n",
    "inds = np.arange(1, len(additive_runnames)+1)\n",
    "\n",
    "\n",
    "generate_barplots([additive_profits_per_episode, multi_profits_per_episode], inds, colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generate_grouped_bar_plot2(additive_twb_df, additive_twb_df_ci, multi_twb_df, multi_twb_df_ci, inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additive_twb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_twb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_profits(profits_per_episode):\n",
    "    return np.array([df.mean()['Profits'] for df in profits_per_episode])\n",
    "\n",
    "additive_mean_profits = compute_mean_profits(additive_profits_per_episode)\n",
    "multi_mean_profits = compute_mean_profits(multi_profits_per_episode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additive_mean_profits, multi_mean_profits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(additive_mean_profits.mean(), multi_mean_profits.mean())\n",
    "print(additive_mean_profits.std(), multi_mean_profits.std())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "greenlight_gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
