parameters:
    policy: 
        value: MlpPolicy
    normalize_advantage:
        value: True
    ent_coef:
        value: 0.0
    vf_coef:
        value: 0.5
    max_grad_norm:
        value: 0.5
    use_sde:
        value: False
    sde_sample_freq:
        value: -1
    target_kl:
        value: None
    optimizer_class:
        value: ADAM
    optimizer_kwargs: 
        value: 
            amsgrad: True
    n_steps: 
        value: 192
    batch_size:
        value: 64
    n_epochs:
      value: 7
    gamma: 
        value: .95
    gae_lambda: 
        value: .95
    clip_range:
        value: .3
    std_init:
        value: .5
    n_envs:
        value: 12

    learning_rate: 
        distribution: log_uniform_values
        min: 1e-6
        max: 1e-3
    vf_size:
        distribution: categorical
        values: [8, 16, 32, 64, 128, 256, 512]
    pi_size:
        distribution: categorical
        values: [8, 16, 32, 64, 128, 256, 512]
    activation_fn:
        distribution: categorical
        values: [Tanh, SiLU, ELU]
    predHorizon:
        distribution: uniform
        min: 0
        max: 1
